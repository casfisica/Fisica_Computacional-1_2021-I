{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning (Aprendizaje Automático)\r\n",
    "\r\n",
    "# Redes Neuronales\r\n",
    "\r\n",
    "¿Qué es una red neuronal?\r\n",
    "\r\n",
    "La mayoría de los textos introductorios a las redes neuronales plantean analogías cerebrales al describirlos. En un nivel muy simple, las neuronas son básicamente unidades computacionales que toman entradas que se canalizan a salidas. Simplificando se puede describir las redes neuronales como una función matemática que asigna una entrada determinada a una salida deseada.\r\n",
    "\r\n",
    "Los componentes principales de las redes neuronales son:\r\n",
    "- Una _capa de entrada_ (input layer), $x$\r\n",
    "- Una cantidad arbitraria de _capas ocultas_ (hidden layers).\r\n",
    "- Una _capa de salida_ (output layer) o hipótesis, $\\hat{h}$\r\n",
    "- Un conjunto de _pesos y sesgos_ entre cada capa, $\\theta_{ij}$ y $b_i$ \r\n",
    "- Una opción de función de activación para cada capa oculta, $g$.\r\n",
    "\r\n",
    "El siguiente \r\n",
    "\r\n",
    "<!-- begin figure -->\r\n",
    "<div style=\"background-color:rgba(255, 255, 255, 255); text-align:center; vertical-align: middle; padding:40px 0;\">\r\n",
    "  <img src=\"Fig/Neural_Network_1.png\" width=\"600\" height=\"300\" hspace=\"10\"/>\r\n",
    "</div>\r\n",
    "<!-- Caption -->\r\n",
    "&nbsp;\r\n",
    "<TABLE BORDER width=\"750\" align=\"CENTER\" text-align=\"JUSTIFY\" BORDERCOLOR=\"black\">\r\n",
    "  <TR>\r\n",
    "    <TD>\r\n",
    "      Diagrama con la arquitectura de una red neuronal de 2 capas (tenga en cuenta que la capa de entrada generalmente se excluye cuando se cuenta el número de capas en una red neuronal).\r\n",
    "    </TD>\r\n",
    "  </TR>\r\n",
    "</TABLE>\r\n",
    "\r\n",
    "<!-- end figure -->"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Miremos cómo representaremos una función de hipótesis utilizando redes neuronales. En nuestro modelo (ver figura), las entradas $x_1 \\cdots x_nx$, y la salida es el resultado de nuestra función de hipótesis $h$. En este modelo $x_0x en la capa de entrada a veces se denomina \"unidad de sesgo\" (bias). En las redes neuronales, usamos la misma función logística que en la clasificación, \r\n",
    "\r\n",
    "$$g(x)=\\frac {1} {1 + e ^ {-x}}$$\r\n",
    "\r\n",
    "En esta situación, los parámetros \"theta\" a veces se denominan \"pesos\". Los nodos de entrada (capa 1), también conocida como la \"capa de entrada\", van a otro nodo (capa 2), que finalmente genera la función de hipótesis, conocida como \"capa de salida\". Podemos tener capas intermedias de nodos entre las capas de entrada y salida llamadas \"capas ocultas\". En este ejemplo, etiquetamos estos nodos de capa intermedios u \"ocultos\" como $a^ 2_0 \\cdots a^2_n $ tambiien llamados \"unidades de activación\". Para el ejemplo tenemos que $a^{(j)}$ en la unidad de activación $i$-ésima de la capa $j$-ésima. \r\n",
    "\r\n",
    "Los valores de cada nodo de activación se obtienen así (para el caso de $n=3$ y mismos nodos en la capa oculta):\r\n",
    "\r\n",
    "$$\r\n",
    "\\begin{align*}\r\n",
    "a_{1}^{(2)} & =g\\left(\\Theta_{10}^{(1)}x_{0}+\\Theta_{11}^{(1)}x_{1}+\\Theta_{12}^{(1)}x_{2}+\\Theta_{13}^{(1)}x_{3}\\right)\\\\\r\n",
    "a_{2}^{(2)} & =g\\left(\\Theta_{20}^{(1)}x_{0}+\\Theta_{21}^{(1)}x_{1}+\\Theta_{22}^{(1)}x_{2}+\\Theta_{23}^{(1)}x_{3}\\right)\\\\\r\n",
    "a_{3}^{(2)} & =g\\left(\\Theta_{30}^{(1)}x_{0}+\\Theta_{31}^{(1)}x_{1}+\\Theta_{32}^{(1)}x_{2}+\\Theta_{33}^{(1)}x_{3}\\right)\r\n",
    "\\end{align*}\r\n",
    "$$\r\n",
    "\r\n",
    "Donde $\\Theta^{(j)}$ es la matriz de pesos (parámetros) que mapean de la capa $j$ a la capa $j+1$. Esto quiere decir que si la red tiene $s_j$ nodos en la capa $j$ y $s_{(j+1)}$ nodos en la capa $j+1$, entonces calculamos los nodos de activación utilizando una matriz de parámetros de $s_j \\times (1+s_j)$. Cada capa tiene su propia matriz de pesos. El $+1$ proviene de la suma en $\\Theta^{(j)}$ de los \"nodos de sesgo\", $x_0$ y $\\Theta_0^{(j)}$. En otras palabras, los nodos de salida no incluirán los nodos de bias, mientras que las entradas sí.\r\n",
    "\r\n",
    "El resultado de la hipótesis es la función logística aplicada a la suma de los valores de los nodos de activación, que se han multiplicado por otra matriz de parámetros $\\Theta^{(2)}$ que contiene los pesos de la segunda capa de nodos. \r\n",
    "\r\n",
    "$$\r\n",
    "h_\\Theta(x) = g\\left(\\Theta_{10}^{(2)}a^{(2)}_{0}+\\Theta_{11}^{(1)}a^{(2)}_{1}+\\Theta_{12}^{(1)}a^{(2)}_{2}+\\Theta_{13}^{(1)}a^{(2)}_{3}\\right)\r\n",
    "$$\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Ejemplo:__ Miremos como se puede llegar a tener un modelo de clasificación complejo usando una red sencilla. \r\n",
    "\r\n",
    "<!-- begin figure -->\r\n",
    "<div style=\"background-color:rgba(255, 255, 255, 255); text-align:center; vertical-align: middle; padding:40px 0;\">\r\n",
    "  <img src=\"Fig/neural_layer_XNOR.png\" width=\"600\" height=\"300\" hspace=\"10\"/>\r\n",
    "</div>\r\n",
    "<!-- Caption -->\r\n",
    "\r\n",
    "&nbsp;\r\n",
    "&nbsp;\r\n",
    "\r\n",
    "<TABLE BORDER width=\"750\" align=\"CENTER\" text-align=\"JUSTIFY\" BORDERCOLOR=\"black\">\r\n",
    "  <TR>\r\n",
    "    <TD>\r\n",
    "      Diagrama con la arquitectura de una red neuronal de 2 capas que reproduce la función XNOR.\r\n",
    "    </TD>\r\n",
    "  </TR>\r\n",
    "</TABLE>\r\n",
    "\r\n",
    "&nbsp;\r\n",
    "&nbsp;\r\n",
    "<!-- end figure -->\r\n",
    "<div style=\"background-color:rgba(255, 255, 255, 255); text-align:center; vertical-align: middle; padding:40px 0;\">\r\n",
    "  <img src=\"Fig/Sigmoid.png\" width=\"400\" height=\"300\" hspace=\"10\"/>\r\n",
    "</div>\r\n",
    "\r\n",
    "&nbsp;\r\n",
    "&nbsp;\r\n",
    "\r\n",
    "<center>\r\n",
    "\r\n",
    "| $x_1$ | $x_2$ | $a^{(2)}_1$ | $a^{(2)}_2$ | $h_\\Theta(x)$ |\r\n",
    "|:-----:|:-----:|:-----------:|:-----------:|---------------|\r\n",
    "| 0     | 0     | 0           | 1           | 1             |\r\n",
    "| 0     | 1     | 0           | 0           | 0             |\r\n",
    "| 1     | 0     | 0           | 0           | 0             |\r\n",
    "| 1     | 1     | 1           | 0           | 1             |\r\n",
    "\r\n",
    "</center>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clasificación de  multiples clases\r\n",
    "Para clasificar los datos en varias clases, dejamos que nuestra función de hipótesis devuelva un vector de valores. Digamos que queríamos clasificar nuestros datos en una de cuatro categorías, luego podemos definir nuestro conjunto de clases resultantes $y$ como\r\n",
    "$$\r\n",
    "y=\\left[\\begin{array}{c}\r\n",
    "1\\\\\r\n",
    "0\\\\\r\n",
    "0\\\\\r\n",
    "0\r\n",
    "\\end{array}\\right],\\left[\\begin{array}{c}\r\n",
    "0\\\\\r\n",
    "1\\\\\r\n",
    "0\\\\\r\n",
    "0\r\n",
    "\\end{array}\\right],\\left[\\begin{array}{c}\r\n",
    "0\\\\\r\n",
    "0\\\\\r\n",
    "1\\\\\r\n",
    "0\r\n",
    "\\end{array}\\right],\\left[\\begin{array}{c}\r\n",
    "0\\\\\r\n",
    "0\\\\\r\n",
    "0\\\\\r\n",
    "1\r\n",
    "\\end{array}\\right]\r\n",
    "$$\r\n",
    "\r\n",
    "Cada $y^{(i)}$ representa una clase diferente, y cada una de las capas internas nos proporciona información nueva que conduce a la función de hipótesis final."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Función de costo\r\n",
    "Definamos algunas variables\r\n",
    "- m               : número de puntos de entrenamiento\r\n",
    "- $L$             : número total de capas en la red\r\n",
    "- $s_l$           : número de unidades (sin contar la unidad de sesgo) en la capa $l$.\r\n",
    "- $K$             : número de unidades / clases de salida\r\n",
    "- $h_\\Theta(x)_k$ : La hipótesis que da como resultado la $k^{th}$ salida. \r\n",
    "\r\n",
    "La función de costo para redes neuronales será una generalización de la que usamos para la regresión logística (regularizada). \r\n",
    "\r\n",
    "$$\r\n",
    "\\begin{gather*} J(\\Theta) = - \\frac{1}{m} \\sum_{i=1}^m \\sum_{k=1}^K \\left[y^{(i)}_k \\log ((h_\\Theta (x^{(i)}))_k) + (1 - y^{(i)}_k)\\log (1 - (h_\\Theta(x^{(i)}))_k)\\right] + \\frac{\\lambda}{2m}\\sum_{l=1}^{L-1} \\sum_{r=1}^{s_l} \\sum_{j=1}^{s_{l+1}} ( \\Theta_{j,r}^{(l)})^2\\end{gather*}\r\n",
    "$$\r\n",
    "\r\n",
    "__Notas:__ \r\n",
    "- Hay muchas funciones de pérdida disponibles, y generalmente la naturaleza del problema dicta la elección de función de pérdida\r\n",
    "- Una diferencia respecto a la función de costo de la RL, es que se ha agregado la suma para dar cuenta de nuestros múltiples nodos de salida (suma sobre $k$). \r\n",
    "- La otra diferencia es que en la parte de regularización, se debe de tener en cuenta las múltiples matrices $\\Theta$ . \r\n",
    "- El número de columnas en la matriz $\\Theta^{(l)}$ es igual al número de nodos en la capa actual (incluida la unidad de sesgo) i.e. $s_l +1$. \r\n",
    "- El número de filas en es igual al número de nodos en la siguiente capa (excluyendo la unidad de sesgo) i.e. $s_{l+1}$. \r\n",
    "- La suma doble suma los costos de regresión logística calculados para cada unidad (para las clases multiples) en la capa de salida.\r\n",
    "- La suma triple suma los cuadrados de todas las $\\Theta$ s individuales en toda la red."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entrenamiento de la red neuronal\r\n",
    "\r\n",
    "Note arriba el resultado $h_\\Theta(x)$ de una red neuronal simple, los pesos $\\Theta_{ij}$ y los sesgos $\\Theta_{i0}$ son las únicas variables que afectan la salida. Naturalmente, los valores correctos para los pesos y sesgos determinan la fuerza de las predicciones. El proceso de ajuste fino de los pesos y sesgos de los datos de entrada se conoce como entrenamiento de la red neuronal.\r\n",
    "\r\n",
    "Cada iteración del proceso de formación consta de los siguientes pasos:\r\n",
    "- Cálculo de la hipotesis $h_\\Theta(x)$, conocida como _Forward-propagation_ (propagación hacia adelante).\r\n",
    "- Actualización de los parametros y sesgos, conocido como _Back-propagation_\r\n",
    "\r\n",
    "### Algoritmo de Backpropagation\r\n",
    "La \"_Backpropagation_\" es la palabra que se usa en redes neuronales para indicar la minimización de la función de costo, al igual que lo que estábamos haciendo con el descenso por gradiente en la regresión logística y lineal. Es decir, queremos minimizar la función de costo $J$ usando un conjunto óptimo de parámetros en $\\Theta$.\r\n",
    "\r\n",
    "Algoritmo:\r\n",
    "\r\n",
    "1. Dado un conjunto de entrenamiento $\\lbrace(x^{(1)}, y^{(1)}) \\cdots (x^{(m)}, y^{(m)}) \\rbrace$, establecer $\\Delta^{(l)}_{i, j}$ para todo $(l, i, j)$ ( $\\Delta^{(l)}_{i, j}$ es una matriz llena de ceros)\r\n",
    "2. Para el ejemplo de entrenamiento $t= 1,...,m$ :\r\n",
    "    - $ a^{(1)}:= x^{(t)}$.\r\n",
    "    - Realice la propagación hacia adelante para calcular $ a^{(l)}$ para $l = 2,3,…,L$.\r\n",
    "3. Calcule el error en la última capa $\\delta^{(L)}=a^{(L)}-y^{(t)}$. Donde $L$ es el número total de capas y $a^{(L)}$ es el vector de salidas de las unidades de activación para la última capa, luego loserrores para la última capa son las diferencias de los resultados de la hipotesis en la última capa y las salidas correctas $y$. \r\n",
    "4. Para obtener los valores $\\delta^{(L-1)}, \\delta^{(L-2)},\\dots,\\delta^{(2)}$ de las capas antes de la última, usamos la ecuación: $$\\delta^{(l)} = ((\\Theta^{(l)})^T \\delta^{(l+1)})\\times g'(z^{(l)}),$$ donde los valores $\\delta$ de la capa $l$ se calculan multiplicando los valores $\\delta$ en la siguiente capa con la matriz $\\theta$ de la capa $l$. Luego multiplicamos esto por cada elemento (elemt-wise $\\times$) del vector de que genera la función $g'$, o $g$-prima, que es la derivada de la función de activación $g$ evaluada con los valores de entrada dados por $z^{(l)}$. Para nuestro caso $$g'(z^{(l)}) = a^{(l)}\\times(1 - a^{(l)})$$\r\n",
    "5. Calculo para cada capa $\\Delta^{(l)} := \\Delta^{(l)} + \\delta^{(l+1)}(a^{(l)})^T$, y se actualiza con estas matrices $\\Delta$ las matrices regularizadas $D^{(l)}_{i,j}$\r\n",
    "    - $ D^{(l)}_{i,j} := \\dfrac{1}{m}\\left(\\Delta^{(l)}_{i,j} + \\lambda\\Theta^{(l)}_{i,j}\\right)$ si $j \\neq 0$.\r\n",
    "    - $ D^{(l)}_{i,j} := \\dfrac{1}{m}\\Delta^{(l)}_{i,j}$ si $j=0$\r\n",
    "\r\n",
    "La matriz $D$ se utiliza como un \"acumulador\" para sumar los valores a medida que avanzamos y, finalmente, calcular nuestra derivada parcial. Así obtenemos $$\\frac{\\partial}{\\partial \\Theta_{ij}^{(l)}} J(\\Theta)= D_{ij}^{(l)}$$\r\n",
    "\r\n",
    "Con esta derivada podemos hacer GD.\r\n",
    "\r\n",
    "$$\r\n",
    "\\theta^{(l)}_{ij}: = \\theta^{(l)}_{ij}-\\alpha D_{ij}^{(l)}\r\n",
    "$$\r\n",
    "\r\n",
    "​\r\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "ef4c800377bbf5e33c22b32317d08627756e48ff809c13c8c6fbaacd1e58e059"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}