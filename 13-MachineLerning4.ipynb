{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning (Aprendizaje Automático)\r\n",
    "\r\n",
    "# sklearn\r\n",
    "`scikit-learn` (anteriormente `scikits.learn`) es una librería de software libre para aprendizaje automático. Cuenta con varios algoritmos de clasificación, regresión y análisis de grupos entre los cuales están máquinas de soporte vectorial, arboles de decisión, Gradient boosting, K-means y DBSCAN. Está diseñada para interoperar con las bibliotecas numéricas y científicas NumPy y SciPy.\r\n",
    "\r\n",
    "Usaremos bases de datos de https://www.kaggle.com/\r\n",
    "## Regresión lineal"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Importamos la base de datos\r\n",
    "dataset = pd.read_csv('DataBases/Notas.csv')\r\n",
    "#Vemos que forma tiene\r\n",
    "dataset.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Ahora vemos la primera parte\r\n",
    "dataset.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig1, ax1 = plt.subplots(figsize=(10, 6))\r\n",
    "ax1.set(xlabel=\"Horas\",ylabel=\"Nota porcentual\")\r\n",
    "dataset.plot(x='Horas', y='Notas', style='o', ax = ax1)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora tenemos una idea sobre los detalles estadísticos de nuestros datos. El siguiente paso es dividir los datos en \"caracteristicas\" (atributos, variables) y \"resultados\" (etiquetas). En el conjunto de datos solo tenemos dos columnas. Queremos predecir la puntuación porcentual en función de las horas estudiadas. Por lo tanto, nuestro conjunto de atributos consistirá en la columna \"Horas\" y la etiqueta será la columna \"Puntuación\"."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Separamos caracteristicas de resultados\r\n",
    "X = dataset.iloc[:, :-1].values\r\n",
    "y = dataset.iloc[:, 1].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora que tenemos nuestros atributos y etiquetas, el siguiente paso es dividir estos datos en conjuntos de prueba y entrenamiento. Se puede hacer esto usando el método `train_test_split()` que viene dentro de `scikit-Learn`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Divido el 80% de los datos en el conjunto de entrenamiento, y el 20% de los datos en el conjunto de prueba. \r\n",
    "# La variable test_size es donde realmente especificamos la proporción del conjunto de prueba.\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Entrenando el algoritmo\r\n",
    "Con Scikit-Learn es simple implementar modelos de regresión lineal, ya que todo lo que realmente necesita hacer es importar la clase `LinearRegression`, instanciarla y llamar al método `fit()` junto con nuestros datos de entrenamiento. \r\n",
    "\r\n",
    "La regresión lineal básicamente encuentra el mejor valor para la intersección y la pendiente, lo que da como resultado una línea que se ajusta mejor a los datos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Importo LinearRegression\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "# Instancio\r\n",
    "regressor = LinearRegression()\r\n",
    "# LLamo al metodo fit y le paso los datos de entrenamiento\r\n",
    "regressor.fit(X_train, y_train)\r\n",
    "# Ahora miro el intercepto y la pendiente de la linea\r\n",
    "print(f\"b = {regressor.intercept_:.3f}, m = {regressor.coef_[0]:.3f}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esto significa que por cada unidad de cambio en las horas estudiadas, el cambio en la puntuación es de aproximadamente 9,91%. O en palabras más simples, si un estudiante estudia una hora más de lo que estudió anteriormente para un examen, puede esperar lograr un aumento del 9,91% en la puntuación obtenida anteriormente.\r\n",
    "\r\n",
    "### Haciendo predicciones\r\n",
    "Ahora que entrenamos el algoritmo, es hora de hacer algunas predicciones. Para hacerlo, usaremos los datos de prueba y veremos con qué precisión se predice la puntuación porcentual. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig2, ax2 = plt.subplots(figsize=(10, 6))\r\n",
    "ax2.set(xlabel=\"Horas\",ylabel=\"Nota porcentual\")\r\n",
    "dataset.plot(x='Horas', y='Notas', style='o', ax = ax2)\r\n",
    "ax2.plot(X_test, regressor.predict(X_test),label=r'$h_{\\theta}(x)$' )\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Y_pred es una matriz de numpy que contiene todos los valores predichos para los valores de entrada en la serie X_test.\r\n",
    "y_pred = regressor.predict (X_test)\r\n",
    "df = pd.DataFrame({'Real': y_test, 'Predicha': y_pred})\r\n",
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluación del algoritmo\r\n",
    "El último paso es evaluar el rendimiento del algoritmo. Este paso es particularmente importante para comparar qué tan bien funcionan los diferentes algoritmos en un conjunto de datos en particular. Para los algoritmos de regresión, se utilizan comúnmente tres métricas de evaluación:\r\n",
    "\r\n",
    "- El error absoluto medio (MAE) es la media del valor absoluto de los errores. Se calcula como:\r\n",
    "\r\n",
    "$$\\frac{1}{n}\\sum_{i=1}^n|y_{real}-y_{pred}|$$\r\n",
    "\r\n",
    "- El error cuadrático medio (MSE) es la media de los errores cuadráticos y se calcula como:\r\n",
    "\r\n",
    "$$\\frac{1}{n}\\sum_{i=1}^n|y_{real}-y_{pred}|^2$$\r\n",
    "\r\n",
    "- El error cuadrático medio (RMSE) es la raíz cuadrada de la media de los errores cuadráticos:\r\n",
    "\r\n",
    "$$\\sqrt{\\frac{1}{n}\\sum_{i=1}^n|y_{real}-y_{pred}|^2}$$\r\n",
    "\r\n",
    "Lo bueno es que no tenemos que realizar estos cálculos manualmente. `scikit-Learn` viene con funciones predefinidas que pueden usarse para calcular estos valores por nosotros."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn import metrics\r\n",
    "print(f\"MAE : {metrics.mean_absolute_error(y_test, y_pred):.4f}\")\r\n",
    "print(f'MSE : {metrics.mean_squared_error(y_test, y_pred):.3f}')\r\n",
    "print(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_test, y_pred)):.4f}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regresión lineal a múltiples variables\r\n",
    "\r\n",
    "Casi todos los problemas del mundo real que se van a encontrar tendrán más de dos variables. La regresión lineal que involucra múltiples variables se denomina \"regresión lineal múltiple\". Los pasos para realizar la regresión lineal múltiple son casi iguales a los de la regresión lineal simple. La diferencia radica en la evaluación. Puede usarlo para averiguar qué factor tiene el mayor impacto en el resultado previsto y cómo se relacionan las diferentes variables entre sí.\r\n",
    "\r\n",
    "__Ejemplo:__ Utilizaremos regresión lineal múltiple para predecir el consumo de gasolina (en millones de galones) en 48 estados de EE. UU. Con base en los impuestos a la gasolina (en centavos), el ingreso per cápita (dólares), las carreteras pavimentadas (en millas) y la proporción de población que tiene licencia de conducir.\r\n",
    "\r\n",
    "Base de datos: _Helmut Spaeth, Mathematical Algorithms for Linear Regression, Academic Press, 1991, ISBN 0-12-656460-4._"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Importamos la base de datos\r\n",
    "dataset1 = pd.read_csv('DataBases/ConsumoGasolina.csv')\r\n",
    "#Vemos que forma tiene\r\n",
    "print(dataset1.shape)\r\n",
    "#Y vemos la primera parte\r\n",
    "dataset1.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cambiamos los nombres de las columnas a español. Luego vemos los detalles estadísticos del conjunto de datos, usando el comando `describe()`. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NewNames = [\"Impuestos_gasolina\", \"Ingresos_medios\", \"Carreteras_pavimentadas\", \"Poblacion_con_licencia(%)\", \"Consumo_gasolina\"]\r\n",
    "dataset1.set_axis(NewNames,axis=1,inplace=True)\r\n",
    "dataset1.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "El siguiente paso es dividir los datos en caracteristicas y etiquetas como hicimos anteriormente, pero a diferencia del ejemplo anterior, usaremos nombres de columna para crear un conjunto de atributos y una etiqueta. Luego entrenamos el algoritmo de manera similar."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Atributos y Etiqueta\r\n",
    "X1 = dataset1[['Impuestos_gasolina', 'Ingresos_medios', 'Carreteras_pavimentadas', 'Poblacion_con_licencia(%)']]\r\n",
    "y1 = dataset1['Consumo_gasolina']\r\n",
    "#Dividimos los datos en entrenamiento y testeo\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=0)\r\n",
    "#Entrenamos el algoritmo\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "regressor1 = LinearRegression()\r\n",
    "regressor1.fit(X1_train, y1_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "En caso de regresión lineal multivariable, el modelo de regresión tiene que encontrar los coeficientes más óptimos para todos los atributos. Para ver qué coeficientes ha elegido nuestro modelo de regresión, usamos `coef_`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coeff_df = pd.DataFrame(regressor1.coef_, X1.columns, columns=['Coeficientes'])\r\n",
    "coeff_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esto significa que por un aumento unitario en \"Impuestos a la gasolina\", hay una disminución de 40.016 millones de galones en el consumo de ésta. De manera similar, un aumento unitario en la proporción de la población con licencia de conducir resulta en un aumento de 1.341 miles de millones de galones de consumo de gasolina. Podemos ver que  los \"Ingresos medios\" y las \"Carreteras pavimentadas\" tienen muy poco efecto en el consumo de gasolina.\r\n",
    "\r\n",
    "Miremos que tan buenas predicciones hace este modelo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y1_pred = regressor1.predict(X1_test)\r\n",
    "df1 = pd.DataFrame({'Real': y1_test, 'Predicha': y1_pred})\r\n",
    "df1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn import metrics\r\n",
    "print(f\"MAE : {metrics.mean_absolute_error(y1_test, y1_pred):.4f}\")\r\n",
    "print(f'MSE : {metrics.mean_squared_error(y1_test, y1_pred):.3f}')\r\n",
    "print(f'RMSE: {np.sqrt(metrics.mean_squared_error(y1_test, y1_pred)):.4f}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regresión logística\r\n",
    "\r\n",
    "Vamos a usar `scikit-learn` para construir el modelo de predicción de la diabetes gestacional, usando una base de datos.\r\n",
    "\r\n",
    "Primero cargamos el conjunto de datos usando `pandas`, como anteriormente. Cambiamos las columnas a español y luego dividimos las columnas dadas en dos tipos de variables dependientes (destino, etiqueta) y variables independientes (características)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Importamos la base de datos\r\n",
    "dataset2 = pd.read_csv('DataBases/diabetes.csv')\r\n",
    "#Vemos que forma tiene\r\n",
    "print(dataset2.shape)\r\n",
    "#Y vemos la primera parte\r\n",
    "dataset2.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NewCol=[\"Semanas_Embarazo\", \"Glucosa\", \"Presion_sanguinea\", \"Espesor_Piel\", \"Insulina\", \"IMC\", \"Funcion_Pedigri_Diabetes\", \"Edad\", \"Resultado\"]\r\n",
    "dataset2.set_axis(NewCol,axis=1,inplace=True)\r\n",
    "dataset2.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Divido la base de datos en variables y respuestas\r\n",
    "Caracteristicas = [\"Semanas_Embarazo\", \"Glucosa\", \"Presion_sanguinea\", \"Espesor_Piel\", \"Insulina\", \"IMC\", \"Funcion_Pedigri_Diabetes\", \"Edad\"]\r\n",
    "X2 = dataset2[Caracteristicas]\r\n",
    "y2 = dataset2.Resultado"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como se hizo anteriormente, y para comprender el rendimiento del modelo, se divide el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba. Usando la función `train_test_split()`. Aquí, el conjunto de datos se divide en dos partes, el 75% de los datos se utilizarán para el entrenamiento de modelos y el 25% para las pruebas de modelos.\r\n",
    "\r\n",
    "__Nota:__ `random_state` es para seleccionar registros al azar."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# dividir X2 e y2 en conjuntos de entrenamiento y prueba\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X2_train,X2_test,y2_train,y2_test=train_test_split(X2,y2,test_size=0.25,random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como con la regreción lineal, primero, importo el módulo Regresión logística y cree un objeto clasificador de Regresión logística utilizando la función `LogisticRegression()`. Luego, ajusto el modelo en el conjunto de entrenamiento usando `fit()` y realice la predicción en el conjunto de prueba usando `predict()`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# importo la clase LogisticRegression\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "\r\n",
    "# instancio el objeto, cambio la cantidad maxima de iteraciones, pues no alcanza a converger con las que tiene por defecto\r\n",
    "logreg = LogisticRegression(max_iter=100000)\r\n",
    "\r\n",
    "# Entreno el modelo con los datos\r\n",
    "logreg.fit(X2_train,y2_train)\r\n",
    "\r\n",
    "#Hago las predicciones con los datos de prueba\r\n",
    "y2_pred=logreg.predict(X2_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para evaluar el desempeño de un modelo de clasificación se usa una matriz de confusión. Lo fundamental de una matriz de confusión es el número de predicciones correctas e incorrectas que se resumen por clases."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# importo la clase metrics\r\n",
    "from sklearn import metrics\r\n",
    "cnf_matrix = metrics.confusion_matrix(y2_test, y2_pred)\r\n",
    "cnf_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se puede ver la matriz de confusión en forma de objeto de numpy. La dimensión de esta matriz es $2 \\times 2$ ya que este modelo es una clasificación binaria (Tiene dos clases 0 y 1). Los valores diagonales representan predicciones precisas, mientras que los elementos no diagonales son predicciones inexactas. En la salida, 117 y 36 son predicciones reales, y 26 y 13 son predicciones incorrectas.\r\n",
    "\r\n",
    "__Nota:__ errores de Tipo I y Tipo II. Estos términos, que no son exclusivos de los problemas de clasificación en el aprendizaje automático, también son extremadamente importantes cuando se trata de pruebas de hipótesis estadísticas.\r\n",
    "\r\n",
    "- _Error tipo I:_ falso positivo (rechazo de una verdadera hipótesis nula)\r\n",
    "\r\n",
    "- _Error de tipo II:_ falso negativo (no rechazo de una hipótesis nula falsa)\r\n",
    "\r\n",
    "<!-- begin figure -->\r\n",
    "<div id=\"\"></div>\r\n",
    "<img src=\"Fig/MatrizDeConf.png\" width=600>\r\n",
    "<p></p>\r\n",
    "<!-- end figure -->\r\n",
    "\r\n",
    "Se puede visualizar la matriz de confusión mediante un mapa de calor. Visualicemos los resultados del modelo en usando la matriz de confusión con matplotlib y seaborn."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "# Nombres de las clases\r\n",
    "class_names=[0,1] \r\n",
    "fig, ax = plt.subplots()\r\n",
    "tick_marks = np.arange(len(class_names))\r\n",
    "plt.xticks(tick_marks, class_names)\r\n",
    "plt.yticks(tick_marks, class_names)\r\n",
    "# Mapa de calor\r\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\r\n",
    "ax.xaxis.set_label_position(\"top\")\r\n",
    "plt.tight_layout()\r\n",
    "\r\n",
    "plt.ylabel('Real')\r\n",
    "plt.xlabel('Predicho')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tambien podemos usar métricas de evaluación de la matriz de confusión. Evaluemos el modelo utilizando exactitud, precisión, recall y F1.\r\n",
    "\r\n",
    "__Exactitud:__ Generalmente se calcula como $\\frac{N_{Correctos}}{N_{Total}}$, pero cuando se trata de problemas de clasificación, intentamos predecir un resultado binario. ¿Es un fraude o no? ¿Esta persona incumplirá con su préstamo o no? Etc. Entonces, lo que nos importa, además de esta proporción general, son las predicciones numéricas que se clasificaron falsamente como positivas y como negativas. \r\n",
    "\r\n",
    "$$E = \\frac{N_{TP}+N_{TN}}{N_{Total}}$$\r\n",
    "\r\n",
    "\r\n",
    "__Precisión:__ Cuando un modelo hace una predicción, con qué frecuencia es correcta, o porcentage de relevancia del resultado. \r\n",
    "\r\n",
    "$$P = \\frac{N_{TP}}{N_{Total}}$$\r\n",
    "\r\n",
    "__Recall:__  Número de verdaderos positivos sobre resultados predichos (verdaderos positivos mas falsos negativos). Porcentaje de resultados relevantes que están clasificados correctamente por el modelo que está ejecutando.\r\n",
    "\r\n",
    "$$R = TPR = \\frac{N_{TP}}{N_{TP}+N_{FN}}$$\r\n",
    "\r\n",
    "__F1:__ Tiene en cuenta tanto la precisión como el recall para, en última instancia, medir la precisión del modelo. La diferencia entre esta métrica y la precisiónes que los falsos positivos y los falsos negativos pueden ser absolutamente cruciales para el estudio, mientras que los verdaderos negativos a menudo son menos importantes para cualquier problema que esté tratando de resolver. La puntuación F1 intenta tener esto en cuenta, dando más peso a los falsos negativos y falsos positivos sin dejar que un gran número de verdaderos negativos influya en su puntuación.\r\n",
    "\r\n",
    "$$F1= 2\\frac{P\\times R}{P + R}$$\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Exactitud:\",metrics.accuracy_score(y2_test, y2_pred))\r\n",
    "print(\"Precision:\",metrics.precision_score(y2_test, y2_pred))\r\n",
    "print(\"Recall   :\",metrics.recall_score(y2_test, y2_pred))\r\n",
    "print(\"F1       :\",metrics.f1_score(y2_test, y2_pred))\r\n",
    "#Tambien se puede hacer con classification_report\r\n",
    "print(metrics.classification_report(y2_test, y2_pred))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una tasa de clasificación del 80%, es considerada como buena exactitud. Cuando el modelo de regresión logística predijo que los pacientes van a padecer diabetes, los pacientes tienen el 73% del tiempo. Si hay pacientes que tienen diabetes en el conjunto de prueba, el modelo de regresión logística puede identificarlo el 58% de las veces.\r\n",
    "\r\n",
    "### Curva ROC\r\n",
    "La Receiver Operating Characteristic (ROC) es un gráfico de la tasa de verdaderos positivos frente a la tasa de falsos positivos. Muestra la compensación entre sensibilidad y especificidad.\r\n",
    "- La sensibilidad nos indica la capacidad de nuestro estimador para dar como casos positivos los casos realmente positivos; e.g. proporción de enfermos correctamente identificados. Es decir, la sensibilidad caracteriza la capacidad de la prueba para detectar la enfermedad en sujetos enfermos.\r\n",
    "- La especificidad nos indica la capacidad de nuestro estimador para dar como casos negativos los casos realmente negativos; e.g. proporción de sanos correctamente identificados. Es decir, la especificidad caracteriza la capacidad de la prueba para detectar la ausencia de la enfermedad en sujetos sanos.\r\n",
    "\r\n",
    "La curva AUC - ROC es una medida de rendimiento para los problemas de clasificación. ROC es una curva de probabilidad y AUC representa el grado o medida de separabilidad. Indica cuánto es capaz el modelo de distinguir entre clases. Cuanto mayor sea el AUC, mejor será el modelo para predecir 0 clases como 0 y 1 clases como 1. \r\n",
    "La curva ROC se traza con True Positive Rate (TPR) (recall o sensitividad) contra el False Positive Rate (FPR) (1- especificidad) donde TPR está en el eje y y FPR está en el eje x.\r\n",
    "\r\n",
    "$$FPR = \\frac{N_{FP}}{N_{TN}+N_{FP}}$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#predict_proba da la probabilidad de que dado un valor el resultado sea 0 o 1 (depende de la clasificacion)\r\n",
    "#Tomo la segunda columna (probabilidad de 1)\r\n",
    "y_pred_proba = logreg.predict_proba(X2_test)[::,1]\r\n",
    "# Calculo la curva roc\r\n",
    "fpr, tpr, _ = metrics.roc_curve(y2_test,  y_pred_proba)\r\n",
    "# Calculo la puntuacion roc\r\n",
    "auc = metrics.roc_auc_score(y2_test, y_pred_proba)\r\n",
    "#Grafico\r\n",
    "fig3, ax3 = plt.subplots(figsize=(10, 6))\r\n",
    "ax3.plot(fpr,tpr,label=\"Datos, auc=\"+str(f\"{auc:.2f}\"))\r\n",
    "ax3.set(xlabel='FPR',ylabel='TPR')\r\n",
    "ax3.legend(loc=4)\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "La puntuación AUC para el caso es 0,86. La puntuación AUC igual a 1 representa un clasificador perfecto y 0,5 representa un clasificador que no dice nada."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "ef4c800377bbf5e33c22b32317d08627756e48ff809c13c8c6fbaacd1e58e059"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}